{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CATastrophe Model Testing - C/C++ Vulnerability Detection\n",
    "\n",
    "This notebook demonstrates testing the CATastrophe vulnerability detection model with proper C/C++ code examples.\n",
    "\n",
    "## Overview\n",
    "- Load the pre-trained model from HuggingFace Hub (`ewhk9887/CATastrophe`)\n",
    "- Test with real C/C++ vulnerability patterns\n",
    "- Visualize results and model performance\n",
    "- Analyze C-specific security patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages for Google Colab\n",
    "!pip install huggingface-hub scikit-learn torch numpy pandas matplotlib seaborn -q\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from typing import List, Tuple\n",
    "import torch\n",
    "import pickle\n",
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "# Set style\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "\n",
    "print(\"‚úì All imports successful!\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"Device available: {'GPU' if torch.cuda.is_available() else 'CPU'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the autoencoder model architecture\n",
    "class EnhancedAutoencoder(torch.nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(EnhancedAutoencoder, self).__init__()\n",
    "        \n",
    "        # Encoder with batch normalization and dropout\n",
    "        self.encoder = torch.nn.Sequential(\n",
    "            torch.nn.Linear(input_dim, 1024),\n",
    "            torch.nn.BatchNorm1d(1024),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(0.2),\n",
    "            \n",
    "            torch.nn.Linear(1024, 512),\n",
    "            torch.nn.BatchNorm1d(512),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(0.2),\n",
    "            \n",
    "            torch.nn.Linear(512, 256),\n",
    "            torch.nn.BatchNorm1d(256),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(0.2),\n",
    "            \n",
    "            torch.nn.Linear(256, 128),\n",
    "            torch.nn.BatchNorm1d(128),\n",
    "            torch.nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # Decoder with batch normalization\n",
    "        self.decoder = torch.nn.Sequential(\n",
    "            torch.nn.Linear(128, 256),\n",
    "            torch.nn.BatchNorm1d(256),\n",
    "            torch.nn.ReLU(),\n",
    "            \n",
    "            torch.nn.Linear(256, 512),\n",
    "            torch.nn.BatchNorm1d(512),\n",
    "            torch.nn.ReLU(),\n",
    "            \n",
    "            torch.nn.Linear(512, 1024),\n",
    "            torch.nn.BatchNorm1d(1024),\n",
    "            torch.nn.ReLU(),\n",
    "            \n",
    "            torch.nn.Linear(1024, input_dim),\n",
    "            torch.nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "\n",
    "# Define the CodeVectorizer class (wrapper for TfidfVectorizer)\n",
    "class CodeVectorizer:\n",
    "    def __init__(self, max_features=2000):\n",
    "        from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "        self.vectorizer = TfidfVectorizer(\n",
    "            max_features=max_features,\n",
    "            token_pattern=r'[a-zA-Z_][a-zA-Z0-9_]*|[^\\w\\s]',\n",
    "            lowercase=True,\n",
    "            use_idf=True,\n",
    "            smooth_idf=True,\n",
    "            sublinear_tf=True,\n",
    "            analyzer='word',\n",
    "            ngram_range=(1, 2),\n",
    "            min_df=2,\n",
    "            max_df=0.95\n",
    "        )\n",
    "        \n",
    "    def fit_transform(self, texts):\n",
    "        return self.vectorizer.fit_transform(texts)\n",
    "    \n",
    "    def transform(self, texts):\n",
    "        return self.vectorizer.transform(texts)\n",
    "\n",
    "# Load model function\n",
    "def load_model_from_hub(repo_id=\"ewhk9887/CATastrophe\"):\n",
    "    \"\"\"Load model and vectorizer from Hugging Face Hub\"\"\"\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    # Download model weights\n",
    "    weights_path = hf_hub_download(repo_id=repo_id, filename=\"autoencoder_weights.pth\")\n",
    "    \n",
    "    # Download vectorizer\n",
    "    vectorizer_path = hf_hub_download(repo_id=repo_id, filename=\"vectorizer.pkl\")\n",
    "    \n",
    "    # Load vectorizer\n",
    "    with open(vectorizer_path, 'rb') as f:\n",
    "        vectorizer = pickle.load(f)\n",
    "    \n",
    "    # Get input dimension from vectorizer\n",
    "    input_dim = len(vectorizer.vectorizer.get_feature_names_out())\n",
    "    \n",
    "    # Initialize model\n",
    "    model = EnhancedAutoencoder(input_dim)\n",
    "    \n",
    "    # Load weights with map_location for CPU/GPU compatibility\n",
    "    state_dict = torch.load(weights_path, map_location=device)\n",
    "    model.load_state_dict(state_dict)\n",
    "    \n",
    "    # Move model to device and set to eval mode\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    return model, vectorizer\n",
    "\n",
    "# Prediction function\n",
    "def predict_score(message, func, model=None, vectorizer=None):\n",
    "    \"\"\"Calculate anomaly score for given code\"\"\"\n",
    "    global _cached_model, _cached_vectorizer\n",
    "    \n",
    "    # Use cached model if not provided\n",
    "    if model is None or vectorizer is None:\n",
    "        if '_cached_model' not in globals():\n",
    "            _cached_model, _cached_vectorizer = load_model_from_hub()\n",
    "        model = _cached_model\n",
    "        vectorizer = _cached_vectorizer\n",
    "    \n",
    "    device = next(model.parameters()).device\n",
    "    \n",
    "    # Combine message and function\n",
    "    combined_text = f\"{message} {func}\"\n",
    "    \n",
    "    # Vectorize\n",
    "    features = vectorizer.transform([combined_text])\n",
    "    \n",
    "    # Convert to tensor\n",
    "    features_tensor = torch.FloatTensor(features.toarray()).to(device)\n",
    "    \n",
    "    # Get reconstruction\n",
    "    with torch.no_grad():\n",
    "        reconstruction = model(features_tensor)\n",
    "    \n",
    "    # Calculate reconstruction error (MSE)\n",
    "    mse = torch.nn.functional.mse_loss(reconstruction, features_tensor, reduction='none')\n",
    "    score = mse.mean(dim=1).item()\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the CATastrophe Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading CATastrophe model from HuggingFace Hub...\")\n",
    "print(\"Repository: ewhk9887/CATastrophe\")\n",
    "print(\"This may take a moment on first run...\\n\")\n",
    "\n",
    "# Load model and vectorizer from Hugging Face Hub\n",
    "model, vectorizer = load_model_from_hub(\"ewhk9887/CATastrophe\")\n",
    "\n",
    "print(f\"\\n‚úì Model loaded successfully!\")\n",
    "print(f\"Model type: {type(model).__name__}\")\n",
    "print(f\"Vectorizer type: {type(vectorizer).__name__}\")\n",
    "print(f\"Input dimensions: {model.encoder[0].in_features}\")\n",
    "print(f\"Model device: {next(model.parameters()).device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define C/C++ Test Cases\n",
    "\n",
    "Real C/C++ code examples with various vulnerability types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define test cases with C/C++ vulnerability types\n",
    "test_cases = [\n",
    "    # Buffer Overflow vulnerabilities\n",
    "    {\n",
    "        \"category\": \"Buffer Overflow\",\n",
    "        \"vulnerable\": True,\n",
    "        \"message\": \"fix buffer overflow in string copy\",\n",
    "        \"func\": \"\"\"void copy_string(char *dest, char *src) {\n",
    "    strcpy(dest, src);\n",
    "}\"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"category\": \"Buffer Overflow\",\n",
    "        \"vulnerable\": True,\n",
    "        \"message\": \"remove unsafe gets function\",\n",
    "        \"func\": \"\"\"void read_input() {\n",
    "    char buffer[100];\n",
    "    gets(buffer);\n",
    "    printf(\"Input: %s\\n\", buffer);\n",
    "}\"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"category\": \"Buffer Overflow\",\n",
    "        \"vulnerable\": True,\n",
    "        \"message\": \"fix strcat buffer overflow\",\n",
    "        \"func\": \"\"\"void concat_strings(char *dest, char *src) {\n",
    "    strcat(dest, src);\n",
    "}\"\"\"\n",
    "    },\n",
    "    \n",
    "    # Format String vulnerabilities\n",
    "    {\n",
    "        \"category\": \"Format String\",\n",
    "        \"vulnerable\": True,\n",
    "        \"message\": \"fix format string vulnerability\",\n",
    "        \"func\": \"\"\"void log_message(char *user_input) {\n",
    "    printf(user_input);\n",
    "}\"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"category\": \"Format String\",\n",
    "        \"vulnerable\": True,\n",
    "        \"message\": \"secure fprintf call\",\n",
    "        \"func\": \"\"\"void print_error(char *msg) {\n",
    "    fprintf(stderr, msg);\n",
    "}\"\"\"\n",
    "    },\n",
    "    \n",
    "    # Integer Overflow vulnerabilities\n",
    "    {\n",
    "        \"category\": \"Integer Overflow\",\n",
    "        \"vulnerable\": True,\n",
    "        \"message\": \"check integer overflow in malloc\",\n",
    "        \"func\": \"\"\"void allocate_buffer(int size) {\n",
    "    char *buf = malloc(size * sizeof(char));\n",
    "    if (buf) {\n",
    "        memset(buf, 0, size);\n",
    "    }\n",
    "}\"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"category\": \"Array Bounds\",\n",
    "        \"vulnerable\": True,\n",
    "        \"message\": \"add bounds checking for array access\",\n",
    "        \"func\": \"\"\"void process_array(int count) {\n",
    "    int arr[100];\n",
    "    for(int i = 0; i < count; i++) {\n",
    "        arr[i] = i * 2;\n",
    "    }\n",
    "}\"\"\"\n",
    "    },\n",
    "    \n",
    "    # Use After Free vulnerabilities\n",
    "    {\n",
    "        \"category\": \"Use After Free\",\n",
    "        \"vulnerable\": True,\n",
    "        \"message\": \"fix use after free bug\",\n",
    "        \"func\": \"\"\"void cleanup_data(char *ptr) {\n",
    "    free(ptr);\n",
    "    printf(\"Data: %s\\n\", ptr);\n",
    "}\"\"\"\n",
    "    },\n",
    "    \n",
    "    # Null Pointer Dereference\n",
    "    {\n",
    "        \"category\": \"Null Pointer\",\n",
    "        \"vulnerable\": True,\n",
    "        \"message\": \"add null pointer check\",\n",
    "        \"func\": \"\"\"int get_string_length(char *str) {\n",
    "    return strlen(str);\n",
    "}\"\"\"\n",
    "    },\n",
    "    \n",
    "    # SAFE/SECURE code examples\n",
    "    {\n",
    "        \"category\": \"Safe String Copy\",\n",
    "        \"vulnerable\": False,\n",
    "        \"message\": \"implement secure string copy\",\n",
    "        \"func\": \"\"\"void safe_copy_string(char *dest, const char *src, size_t dest_size) {\n",
    "    if (dest && src && dest_size > 0) {\n",
    "        strncpy(dest, src, dest_size - 1);\n",
    "        dest[dest_size - 1] = '\\\\0';\n",
    "    }\n",
    "}\"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"category\": \"Safe Input\",\n",
    "        \"vulnerable\": False,\n",
    "        \"message\": \"use fgets for safe input\",\n",
    "        \"func\": \"\"\"void safe_read_input() {\n",
    "    char buffer[100];\n",
    "    if (fgets(buffer, sizeof(buffer), stdin)) {\n",
    "        buffer[strcspn(buffer, \"\\\\n\")] = '\\\\0';\n",
    "        printf(\"Input: %s\\\\n\", buffer);\n",
    "    }\n",
    "}\"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"category\": \"Safe Printf\",\n",
    "        \"vulnerable\": False,\n",
    "        \"message\": \"use safe printf format\",\n",
    "        \"func\": \"\"\"void safe_log_message(const char *user_input) {\n",
    "    printf(\"%s\", user_input);\n",
    "}\"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"category\": \"Safe Memory\",\n",
    "        \"vulnerable\": False,\n",
    "        \"message\": \"implement safe memory allocation\",\n",
    "        \"func\": \"\"\"void safe_allocate_buffer(size_t size) {\n",
    "    if (size > 0 && size < 1000000) {\n",
    "        char *buf = malloc(size);\n",
    "        if (buf != NULL) {\n",
    "            memset(buf, 0, size);\n",
    "            // use buffer\n",
    "            free(buf);\n",
    "        }\n",
    "    }\n",
    "}\"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"category\": \"Safe Pointer\",\n",
    "        \"vulnerable\": False,\n",
    "        \"message\": \"add null check before strlen\",\n",
    "        \"func\": \"\"\"int safe_get_string_length(const char *str) {\n",
    "    if (str == NULL) {\n",
    "        return 0;\n",
    "    }\n",
    "    return strlen(str);\n",
    "}\"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"category\": \"Safe Bounds\",\n",
    "        \"vulnerable\": False,\n",
    "        \"message\": \"add array bounds validation\",\n",
    "        \"func\": \"\"\"void safe_process_array(int count) {\n",
    "    int arr[100];\n",
    "    if (count > 0 && count <= 100) {\n",
    "        for(int i = 0; i < count; i++) {\n",
    "            arr[i] = i * 2;\n",
    "        }\n",
    "    }\n",
    "}\"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"category\": \"Regular Function\",\n",
    "        \"vulnerable\": False,\n",
    "        \"message\": \"implement factorial function\",\n",
    "        \"func\": \"\"\"int calculate_factorial(int n) {\n",
    "    if (n <= 1) {\n",
    "        return 1;\n",
    "    }\n",
    "    return n * calculate_factorial(n - 1);\n",
    "}\"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"category\": \"Regular Function\",\n",
    "        \"vulnerable\": False,\n",
    "        \"message\": \"add array sum utility\",\n",
    "        \"func\": \"\"\"int sum_array(const int arr[], int size) {\n",
    "    int sum = 0;\n",
    "    for (int i = 0; i < size; i++) {\n",
    "        sum += arr[i];\n",
    "    }\n",
    "    return sum;\n",
    "}\"\"\"\n",
    "    }\n",
    "]\n",
    "\n",
    "print(f\"Defined {len(test_cases)} C/C++ test cases:\")\n",
    "vulnerable_count = sum(1 for case in test_cases if case['vulnerable'])\n",
    "safe_count = len(test_cases) - vulnerable_count\n",
    "print(f\"- {vulnerable_count} vulnerable C/C++ code samples\")\n",
    "print(f\"- {safe_count} safe C/C++ code samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Predictions on C/C++ Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Running predictions on C/C++ test cases...\\n\")\n",
    "\n",
    "results = []\n",
    "for i, test_case in enumerate(test_cases):\n",
    "    print(f\"[{i+1}/{len(test_cases)}] Testing: {test_case['category']}\")\n",
    "    \n",
    "    # Get prediction score\n",
    "    score = predict_score(test_case['message'], test_case['func'])\n",
    "    \n",
    "    # Store results\n",
    "    results.append({\n",
    "        'category': test_case['category'],\n",
    "        'vulnerable': test_case['vulnerable'],\n",
    "        'score': score,\n",
    "        'message': test_case['message'],\n",
    "        'func_preview': test_case['func'][:80] + '...' if len(test_case['func']) > 80 else test_case['func']\n",
    "    })\n",
    "    \n",
    "    status = \"üî¥ VULNERABLE\" if test_case['vulnerable'] else \"üü¢ SAFE\"\n",
    "    print(f\"    Score: {score:.6f} - {status}\")\n",
    "    print()\n",
    "\n",
    "# Convert to DataFrame for easier analysis\n",
    "df_results = pd.DataFrame(results)\n",
    "print(\"\\n‚úì All predictions completed!\")\n",
    "print(f\"Results stored in DataFrame with {len(df_results)} rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display results summary\n",
    "print(\"üìä C/C++ VULNERABILITY DETECTION RESULTS\")\n",
    "print(\"=\" * 55)\n",
    "\n",
    "# Basic statistics\n",
    "vulnerable_scores = df_results[df_results['vulnerable'] == True]['score']\n",
    "safe_scores = df_results[df_results['vulnerable'] == False]['score']\n",
    "\n",
    "print(f\"\\nüìà Score Statistics:\")\n",
    "print(f\"All samples - Mean: {df_results['score'].mean():.6f}, Std: {df_results['score'].std():.6f}\")\n",
    "print(f\"Vulnerable  - Mean: {vulnerable_scores.mean():.6f}, Std: {vulnerable_scores.std():.6f}\")\n",
    "print(f\"Safe        - Mean: {safe_scores.mean():.6f}, Std: {safe_scores.std():.6f}\")\n",
    "\n",
    "print(f\"\\nüéØ Score Ranges:\")\n",
    "print(f\"Overall: {df_results['score'].min():.6f} - {df_results['score'].max():.6f}\")\n",
    "print(f\"Vulnerable: {vulnerable_scores.min():.6f} - {vulnerable_scores.max():.6f}\")\n",
    "print(f\"Safe: {safe_scores.min():.6f} - {safe_scores.max():.6f}\")\n",
    "\n",
    "# Show results by category\n",
    "print(f\"\\nüìã Results by Category:\")\n",
    "category_summary = df_results.groupby(['category', 'vulnerable'])['score'].agg(['mean', 'count']).round(6)\n",
    "for (category, is_vuln), data in category_summary.iterrows():\n",
    "    status = \"üî¥ Vulnerable\" if is_vuln else \"üü¢ Safe\"\n",
    "    print(f\"  {status} {category}: {data['mean']:.6f} (n={data['count']})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detailed Results Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a detailed results table\n",
    "display_df = df_results.copy()\n",
    "display_df['Status'] = display_df['vulnerable'].map({True: 'üî¥ Vulnerable', False: 'üü¢ Safe'})\n",
    "display_df['Anomaly Score'] = display_df['score'].round(6)\n",
    "display_df = display_df[['category', 'Status', 'Anomaly Score', 'message']]\n",
    "display_df.columns = ['Vulnerability Type', 'Ground Truth', 'Anomaly Score', 'Commit Message']\n",
    "\n",
    "# Sort by score (highest first)\n",
    "display_df = display_df.sort_values('Anomaly Score', ascending=False).reset_index(drop=True)\n",
    "\n",
    "print(\"üìã DETAILED C/C++ VULNERABILITY ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "print(display_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization: Score Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create visualization of results\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "fig.suptitle('CATastrophe Model - C/C++ Vulnerability Detection Analysis', fontsize=16, fontweight='bold')\n",
    "\n",
    "# 1. Score distribution comparison\n",
    "axes[0, 0].hist(vulnerable_scores, alpha=0.7, label='Vulnerable', color='red', bins=8)\n",
    "axes[0, 0].hist(safe_scores, alpha=0.7, label='Safe', color='green', bins=8)\n",
    "axes[0, 0].set_xlabel('Anomaly Score')\n",
    "axes[0, 0].set_ylabel('Frequency')\n",
    "axes[0, 0].set_title('Score Distribution: Vulnerable vs Safe C Code')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Box plot comparison\n",
    "box_data = [vulnerable_scores, safe_scores]\n",
    "box_plot = axes[0, 1].boxplot(box_data, labels=['Vulnerable', 'Safe'], patch_artist=True)\n",
    "box_plot['boxes'][0].set_facecolor('red')\n",
    "box_plot['boxes'][1].set_facecolor('green')\n",
    "axes[0, 1].set_ylabel('Anomaly Score')\n",
    "axes[0, 1].set_title('Score Distribution by Safety Status')\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Individual sample scores\n",
    "colors = ['red' if v else 'green' for v in df_results['vulnerable']]\n",
    "axes[1, 0].scatter(range(len(df_results)), df_results['score'], c=colors, alpha=0.7, s=60)\n",
    "axes[1, 0].set_xlabel('Sample Index')\n",
    "axes[1, 0].set_ylabel('Anomaly Score')\n",
    "axes[1, 0].set_title('Individual C/C++ Sample Scores')\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Add legend for scatter plot\n",
    "from matplotlib.patches import Patch\n",
    "legend_elements = [Patch(facecolor='red', label='Vulnerable'),\n",
    "                   Patch(facecolor='green', label='Safe')]\n",
    "axes[1, 0].legend(handles=legend_elements)\n",
    "\n",
    "# 4. Vulnerability category scores\n",
    "vuln_categories = df_results[df_results['vulnerable'] == True]\n",
    "category_scores = vuln_categories.groupby('category')['score'].mean().sort_values(ascending=True)\n",
    "\n",
    "axes[1, 1].barh(range(len(category_scores)), category_scores.values, color='red', alpha=0.7)\n",
    "axes[1, 1].set_yticks(range(len(category_scores)))\n",
    "axes[1, 1].set_yticklabels(category_scores.index, fontsize=10)\n",
    "axes[1, 1].set_xlabel('Mean Anomaly Score')\n",
    "axes[1, 1].set_title('Average Scores by Vulnerability Type')\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate some basic performance metrics\n",
    "mean_vuln = vulnerable_scores.mean()\n",
    "mean_safe = safe_scores.mean()\n",
    "separation = mean_vuln - mean_safe\n",
    "\n",
    "print(f\"\\nüìä Key Observations:\")\n",
    "print(f\"‚Ä¢ Mean score for vulnerable code: {mean_vuln:.6f}\")\n",
    "print(f\"‚Ä¢ Mean score for safe code: {mean_safe:.6f}\")\n",
    "print(f\"‚Ä¢ Score separation: {separation:.6f}\")\n",
    "print(f\"‚Ä¢ Higher scores {'DO' if separation > 0 else 'DO NOT'} indicate vulnerabilities\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactive Testing with Custom C Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_c_code(message: str, code: str):\n",
    "    \"\"\"\n",
    "    Analyze custom C/C++ code with the model\n",
    "    \"\"\"\n",
    "    score = predict_score(message, code)\n",
    "    \n",
    "    print(f\"üìù C/C++ Code Analysis\")\n",
    "    print(\"=\" * 40)\n",
    "    print(f\"Commit Message: {message}\")\n",
    "    print(f\"Code Analysis:\")\n",
    "    print(code)\n",
    "    print(f\"\\nAnomaly Score: {score:.6f}\")\n",
    "    \n",
    "    # Compare with our test data\n",
    "    if score > vulnerable_scores.mean():\n",
    "        print(f\"üî¥ HIGH RISK: Score above vulnerable average ({vulnerable_scores.mean():.6f})\")\n",
    "        print(f\"üí° Recommendation: Manual security review recommended\")\n",
    "    elif score > safe_scores.mean():\n",
    "        print(f\"üü° MEDIUM RISK: Score above safe average ({safe_scores.mean():.6f})\")\n",
    "        print(f\"üí° Recommendation: Consider security review\")\n",
    "    else:\n",
    "        print(f\"üü¢ LOW RISK: Score within safe range\")\n",
    "        print(f\"üí° Recommendation: Appears secure\")\n",
    "    \n",
    "    return score\n",
    "\n",
    "# Test examples\n",
    "print(\"üß™ Testing Custom C/C++ Code Samples\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Test 1: Buffer overflow vulnerability\n",
    "print(\"\\nTest 1: Potential Buffer Overflow\")\n",
    "test_code1 = \"\"\"void handle_input(char *user_data) {\n",
    "    char buffer[256];\n",
    "    strcpy(buffer, user_data);\n",
    "    printf(\"Processed: %s\\\\n\", buffer);\n",
    "}\"\"\"\n",
    "analyze_c_code(\"add input processing function\", test_code1)\n",
    "\n",
    "print(\"\\n\" + \"-\"*50)\n",
    "\n",
    "# Test 2: Safe implementation\n",
    "print(\"\\nTest 2: Safe Input Handling\")\n",
    "test_code2 = \"\"\"void safe_handle_input(const char *user_data) {\n",
    "    char buffer[256];\n",
    "    if (user_data && strlen(user_data) < sizeof(buffer)) {\n",
    "        strncpy(buffer, user_data, sizeof(buffer) - 1);\n",
    "        buffer[sizeof(buffer) - 1] = '\\\\0';\n",
    "        printf(\"Processed: %s\\\\n\", buffer);\n",
    "    }\n",
    "}\"\"\"\n",
    "analyze_c_code(\"implement safe input processing\", test_code2)\n",
    "\n",
    "print(\"\\n\" + \"-\"*50)\n",
    "\n",
    "# Test 3: Format string vulnerability\n",
    "print(\"\\nTest 3: Format String Issue\")\n",
    "test_code3 = \"\"\"void debug_log(char *user_msg) {\n",
    "    printf(user_msg);\n",
    "    fflush(stdout);\n",
    "}\"\"\"\n",
    "analyze_c_code(\"add debug logging\", test_code3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Feature Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze what features the model looks for\n",
    "feature_names = vectorizer.vectorizer.get_feature_names_out()\n",
    "print(f\"üîç Model Feature Analysis\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"Total vocabulary features: {len(feature_names):,}\")\n",
    "print(f\"Max features setting: {vectorizer.vectorizer.max_features}\")\n",
    "\n",
    "# Look for C-specific security-related terms\n",
    "security_keywords = {\n",
    "    'Dangerous Functions': ['strcpy', 'strcat', 'sprintf', 'gets', 'scanf'],\n",
    "    'Safe Functions': ['strncpy', 'strncat', 'snprintf', 'fgets'],\n",
    "    'Memory Operations': ['malloc', 'free', 'calloc', 'realloc', 'memcpy', 'memset'],\n",
    "    'Security Terms': ['buffer', 'overflow', 'bounds', 'null', 'pointer', 'check']\n",
    "}\n",
    "\n",
    "print(f\"\\nüéØ Security-Related Features Found:\")\n",
    "for category, keywords in security_keywords.items():\n",
    "    found = []\n",
    "    for keyword in keywords:\n",
    "        matches = [f for f in feature_names if keyword.lower() in f.lower()]\n",
    "        found.extend(matches)\n",
    "    \n",
    "    if found:\n",
    "        print(f\"\\n{category}: {len(found)} features\")\n",
    "        for feature in found[:5]:  # Show first 5\n",
    "            print(f\"  ‚Ä¢ {feature}\")\n",
    "        if len(found) > 5:\n",
    "            print(f\"  ... and {len(found) - 5} more\")\n",
    "    else:\n",
    "        print(f\"\\n{category}: No direct matches found\")\n",
    "\n",
    "# Sample some random features\n",
    "print(f\"\\nüìù Random Sample of Features:\")\n",
    "import random\n",
    "sample_features = random.sample(list(feature_names), min(15, len(feature_names)))\n",
    "for i, feature in enumerate(sample_features):\n",
    "    print(f\"  {feature}\", end=\"   \")\n",
    "    if (i + 1) % 3 == 0:\n",
    "        print()  # New line every 3 features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üéØ CATastrophe Model - C/C++ Security Analysis Summary\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Calculate total parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "\n",
    "print(f\"\\nüèóÔ∏è Model Information:\")\n",
    "print(f\"  ‚Ä¢ Architecture: {type(model).__name__} autoencoder\")\n",
    "print(f\"  ‚Ä¢ Total parameters: {total_params:,}\")\n",
    "print(f\"  ‚Ä¢ Input dimensions: {model.encoder[0].in_features}\")\n",
    "print(f\"  ‚Ä¢ Vocabulary size: {len(feature_names):,} TF-IDF features\")\n",
    "print(f\"  ‚Ä¢ Device: {next(model.parameters()).device}\")\n",
    "\n",
    "print(f\"\\nüìä Performance on C/C++ Test Cases:\")\n",
    "print(f\"  ‚Ä¢ Vulnerable code average score: {vulnerable_scores.mean():.6f}\")\n",
    "print(f\"  ‚Ä¢ Safe code average score: {safe_scores.mean():.6f}\")\n",
    "print(f\"  ‚Ä¢ Score separation: {abs(vulnerable_scores.mean() - safe_scores.mean()):.6f}\")\n",
    "print(f\"  ‚Ä¢ Total test cases: {len(test_cases)} ({vulnerable_count} vulnerable, {safe_count} safe)\")\n",
    "\n",
    "print(f\"\\n‚úÖ Detected Vulnerability Types:\")\n",
    "vuln_types = df_results[df_results['vulnerable'] == True]['category'].value_counts()\n",
    "for vtype, count in vuln_types.items():\n",
    "    avg_score = df_results[(df_results['category'] == vtype) & (df_results['vulnerable'] == True)]['score'].mean()\n",
    "    print(f\"  ‚Ä¢ {vtype}: {count} sample(s), avg score {avg_score:.6f}\")\n",
    "\n",
    "print(f\"\\nüí° Usage Recommendations:\")\n",
    "print(f\"  ‚Ä¢ Use as part of security code review process\")\n",
    "print(f\"  ‚Ä¢ Focus on functions with scores > {vulnerable_scores.mean():.6f}\")\n",
    "print(f\"  ‚Ä¢ Combine with static analysis tools (Clang, Cppcheck)\")\n",
    "print(f\"  ‚Ä¢ Pay special attention to:\")\n",
    "print(f\"    - Buffer operations (strcpy, strcat, gets)\")\n",
    "print(f\"    - Format string usage (printf, fprintf)\")\n",
    "print(f\"    - Memory management (malloc/free patterns)\")\n",
    "print(f\"    - Array bounds checking\")\n",
    "\n",
    "print(f\"\\n‚ö†Ô∏è Important Notes:\")\n",
    "print(f\"  ‚Ä¢ This is an anomaly detection model - manual review is essential\")\n",
    "print(f\"  ‚Ä¢ False positives are possible - use professional judgment\")\n",
    "print(f\"  ‚Ä¢ Best used as a first-line screening tool\")\n",
    "print(f\"  ‚Ä¢ Trained on C code patterns - may not cover all vulnerability types\")\n",
    "\n",
    "print(f\"\\nüöÄ Next Steps:\")\n",
    "print(f\"  ‚Ä¢ Test on your specific C/C++ codebase\")\n",
    "print(f\"  ‚Ä¢ Adjust thresholds based on your needs\")\n",
    "print(f\"  ‚Ä¢ Integrate into CI/CD pipeline\")\n",
    "print(f\"  ‚Ä¢ Train additional models on domain-specific code\")\n",
    "\n",
    "print(f\"\\nüìö Resources:\")\n",
    "print(f\"  ‚Ä¢ Model: https://huggingface.co/ewhk9887/CATastrophe\")\n",
    "print(f\"  ‚Ä¢ Repository documentation: CLAUDE.md\")\n",
    "print(f\"  ‚Ä¢ OWASP C/C++ Security Guidelines\")\n",
    "print(f\"  ‚Ä¢ CERT C Coding Standard\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}